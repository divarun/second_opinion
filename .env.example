# --- LOCAL OLLAMA CONFIGURATION ---
OLLAMA_MODEL_NAME = "llama3" # Use the model name. Update if you want to use a different local model
OLLAMA_BASE_URL = "http://localhost:11434" # Base URL for the Ollama server
OLLAMA_TIMEOUT=120 #Increase Timeout for larger docs

CONFIDENCE_THRESHOLD=0.6
MAX_FAILURE_MODES=10